# Comprehensive SEO Audit Configuration
# Generated by CCC Intelligent Workflow System

metadata:
  name: "comprehensive-seo-audit"
  version: "1.0.0"
  type: "seo"
  complexity: "advanced"
  estimated_duration: "2-4 hours"
  created: "2025-09-06"
  compatible_with: ["claude-code", "autonomous-execution"]

# Agent Configuration
agents:
  coordinator:
    type: "SystemArchitectAgent"
    role: "workflow_orchestration"
    responsibilities:
      - "quality_gate_enforcement"  
      - "agent_handoff_management"
      - "final_integration"
      - "error_recovery"
    
  primary_executor:
    type: "TechnicalSEOAgent"
    role: "technical_analysis"
    stages: [1, 3, 4]
    parallel_capable: true
    responsibilities:
      - "site_crawling"
      - "technical_issue_identification"
      - "schema_analysis"
      - "content_gap_analysis"
    
  competitive_intelligence:
    type: "BenchmarkResearchAgent"  
    role: "competitor_analysis"
    stages: [2]
    parallel_capable: true
    responsibilities:
      - "serp_analysis"
      - "competitor_crawling"
      - "market_positioning"
      - "opportunity_identification"
    
  performance_specialist:
    type: "PerformanceProfilerAgent"
    role: "performance_analysis"
    stages: [4]
    parallel_capable: false
    dependencies: ["stage_1_complete"]
    responsibilities:
      - "core_web_vitals_analysis"
      - "performance_bottleneck_identification"
      - "correlation_analysis"
    
  reporting_specialist:
    type: "MetricsReporterAgent"
    role: "visualization_reporting"
    stages: [5]
    parallel_capable: false
    dependencies: ["all_data_collection_complete"]
    responsibilities:
      - "dashboard_generation"
      - "data_visualization"
      - "executive_summary"
      - "implementation_roadmap"

# MCP Integration Setup
mcps:
  firecrawl:
    priority: "high"
    purpose: "site_crawling_competitor_analysis"
    endpoints:
      - "firecrawl_crawl"
      - "firecrawl_scrape"
    fallback: "manual_sitemap_lighthouse_cli"
    rate_limits:
      requests_per_minute: 60
      concurrent_requests: 5
    
  dataforseo:
    priority: "high"  
    purpose: "serp_analysis_keyword_research"
    endpoints:
      - "serp_google_organic_live"
      - "keywords_google_ads_keywords_for_site"
      - "labs_google_related_keywords"
    fallback: "google_search_console_manual_serp"
    rate_limits:
      requests_per_minute: 100
      concurrent_requests: 3
    
  chart-mcp:
    priority: "medium"
    purpose: "data_visualization"
    endpoints:
      - "generate_chart"
      - "download_chart"
    fallback: "matplotlib_static_charts"
    rate_limits:
      requests_per_minute: 30
      concurrent_requests: 2

# Input Parameter Schema
input_schema:
  required:
    TARGET_URL:
      type: "string"
      validation: "valid_url"
      description: "Primary website to audit"
      example: "https://example.com"
      
    MAIN_KEYWORD:
      type: "string"
      validation: "non_empty"
      min_length: 2
      max_length: 100
      description: "Primary target keyword for competitive analysis"
      example: "digital marketing services"
  
  optional:
    DEVICE:
      type: "enum"
      options: ["mobile", "desktop", "both"]
      default: "both"
      description: "Device type for analysis"
      
    LOCALE:
      type: "string"
      default: "US"
      validation: "iso_country_code"
      description: "Country code for SERP analysis"
      
    CRAWL_DEPTH:
      type: "enum"
      options: ["quick", "standard", "comprehensive"] 
      default: "standard"
      description: "Site crawling depth"
      mapping:
        quick: 2
        standard: 4
        comprehensive: 8
        
    COMPETITOR_COUNT:
      type: "integer"
      default: 5
      min: 3
      max: 10
      description: "Number of top competitors to analyze"

# Stage Configuration
stages:
  stage_1:
    name: "Site Discovery & Technical Crawling"
    agent: "TechnicalSEOAgent"
    duration_minutes: [30, 45]
    parallel: false
    dependencies: []
    success_criteria:
      crawl_completion_rate: ">95%"
      lighthouse_scores: "collected_for_top_pages"
      technical_issues: "categorized_by_severity"
    outputs:
      - "artifacts/crawl_results.json"
      - "artifacts/lighthouse_scores.json"
      - "artifacts/technical_issues.csv"
    
  stage_2:
    name: "Competitive Intelligence"
    agent: "BenchmarkResearchAgent"
    duration_minutes: [25, 40]
    parallel: true
    parallel_with: ["stage_1"]
    dependencies: []
    success_criteria:
      serp_data: "top_10_results_collected"
      competitor_crawl: "{{COMPETITOR_COUNT}}_sites_analyzed"
      competitive_gaps: "identified_and_prioritized"
    outputs:
      - "artifacts/serp_competitors.csv"
      - "artifacts/competitor_analysis.json"
      - "artifacts/competitive_gaps.json"
    
  stage_3:
    name: "Keyword & Content Strategy"
    agent: "TechnicalSEOAgent"
    duration_minutes: [20, 30]
    parallel: false
    dependencies: ["stage_1_complete"]
    success_criteria:
      keyword_opportunities: ">100_researched_terms"
      content_gaps: "themes_identified_with_volume_data"
      keyword_difficulty: "assessed_for_opportunity_terms"
    outputs:
      - "artifacts/keyword_opportunities.csv"
      - "artifacts/content_gaps.json"
      - "artifacts/keyword_strategy.xlsx"
    
  stage_4:
    name: "Performance Deep Dive"
    agent: "PerformanceProfilerAgent"
    duration_minutes: [15, 25]
    parallel: false
    dependencies: ["stage_1_complete"]
    success_criteria:
      cwv_baseline: "established_for_all_page_types"
      performance_issues: "prioritized_by_impact"
      correlation_analysis: "traffic_vs_performance"
    outputs:
      - "artifacts/performance_baseline.csv"
      - "artifacts/cwv_analysis.json"
      - "artifacts/performance_issues.csv"
    
  stage_5:
    name: "Reporting & Deliverables"
    agent: "MetricsReporterAgent"
    duration_minutes: [20, 30]
    parallel: false
    dependencies: ["stage_1_complete", "stage_2_complete", "stage_3_complete", "stage_4_complete"]
    success_criteria:
      dashboard: "interactive_html_with_charts"
      executive_summary: "top_10_issues_prioritized"
      implementation_roadmap: "6_week_plan_with_owners"
    outputs:
      - "reports/seo_audit_dashboard.html"
      - "reports/executive_summary.pdf"
      - "exports/technical_issues.xlsx"
      - "exports/keyword_strategy.xlsx"
      - "exports/performance_baseline.csv"
      - "reports/optimization_roadmap.md"

# Quality Gates & Validation
quality_gates:
  stage_completion:
    crawl_success_rate: 0.95
    api_success_rate: 0.90
    data_completeness: 0.85
    
  final_validation:
    all_artifacts_generated: true
    dashboard_functional: true
    issues_prioritized: true
    roadmap_actionable: true

# Error Handling & Recovery
error_handling:
  crawl_failures:
    max_retries: 3
    backoff_strategy: "exponential"
    fallback_action: "reduce_crawl_depth"
    
  api_rate_limits:
    max_wait_seconds: 300
    backoff_strategy: "exponential"
    retry_attempts: 5
    
  mcp_unavailable:
    action: "switch_to_fallback"
    notify_user: true
    continue_execution: true

# Resource Requirements
resources:
  estimated_api_calls:
    dataforseo: [500, 1000]
    firecrawl: [50, 100]
    chart-mcp: [10, 20]
    
  storage_requirements:
    artifacts: "100-500MB"
    reports: "50-100MB"
    total: "200-600MB"
    
  compute_requirements:
    cpu: "moderate"
    memory: "2-4GB"
    parallel_processing: true

# Success Metrics
success_metrics:
  technical_issues_identified: ">20"
  keyword_opportunities_found: ">100"  
  competitors_analyzed: "{{COMPETITOR_COUNT}}"
  cwv_baseline_established: "all_page_types"
  actionable_roadmap: "6_week_implementation_plan"

# Execution Preferences  
execution:
  auto_parallel: true
  quality_gates_enforced: true
  error_recovery_enabled: true
  progress_reporting: "detailed"
  intermediate_saves: true